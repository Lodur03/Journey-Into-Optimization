{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimização:  Método dos Gradiente Conjugados\n",
    "\n",
    "*Descrição da Tarefa:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementar o método dos *Gradientes Conjugados Não-Linear* e *Método de Descenso Coordenado Sequencial* e utilizá-los para minimizar funções da forma:\n",
    "\n",
    "\n",
    "\n",
    "$$f(x) = e^{\\sum\\limits_{i=1}^n x_i} + \\sum\\limits_{i=1}^na_i x_i^2$$\n",
    "\n",
    "para diferentes valores de $a_i > 0$\n",
    "\n",
    "### **Funções Auxiliares**\n",
    "\n",
    "Vamos definir algumas funções que serão utilizadas posteriormente para facilitar os cálculos do *método gradiente*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "e_values = lambda x: np.ones(len(x))* np.exp(np.sum(x))\n",
    "gradient = lambda x,a: 2*x*a + e_values(x) # retorna lista com os gradientes dado ponto (x,y)\n",
    "apply_func = lambda x,a: np.dot(np.square(x), a) + np.exp(np.sum(x)) # f(x)\n",
    "close_to_zero = lambda grad, tol: np.linalg.norm(grad,2) < tol # stop condition (euclidian distance)\n",
    "hess = lambda x,a: 2*a + e_values(x)\n",
    "max_L = lambda x,a: max(hess(x,a))\n",
    "armijo lambda x, d, step, a, grad, c1: apply_func(x + (d*step),a) >= apply_func(x,a) + c1*step*np.dot(grad, d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções Principais\n",
    "\n",
    "1) Gradiente Conjugado não-linear pelo método de Fletcher-Reeves: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fletcher_reeves(x, a, tolerance=0.00000001, verbose=False, alpha=0.1, backtracking=False, c1 = 0.3, max_it=10000):\n",
    "    \n",
    "    grad = gradient(x,a)\n",
    "    d = -1*grad\n",
    "    beta = 0\n",
    "    it = 0\n",
    "\n",
    "    while((close_to_zero(grad,tolerance) == False) and it < max_it):\n",
    "        \n",
    "        # Choose step size\n",
    "        step = alpha\n",
    "        if(backtracking == True):\n",
    "            while(armijo(x,d, step, a, grad, c1) == True):\n",
    "                step = step/2\n",
    "    \n",
    "        # Update it\n",
    "        x = x + (d*step)\n",
    "        old_grad = grad\n",
    "        grad = gradient(x,a)\n",
    "        beta = np.dot(grad, grad)/np.dot(old_grad, old_grad)\n",
    "        d = -1*grad + beta*d\n",
    "        it = it + 1\n",
    "        \n",
    "    if(verbose == True):\n",
    "        print('Iteracoes utilizadas = ', it)\n",
    "        print('f(x) final = ', apply_func(x,a))\n",
    "        \n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Método de Descenso Coordenado Sequencial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descenso_coordenado(x, a, tolerance=0.0001, verbose=False):\n",
    "    \n",
    "    grad = gradient(x,a)\n",
    "    it = 0\n",
    "\n",
    "    while((close_to_zero(grad,tolerance) == False)):\n",
    "        \n",
    "        index = (it%len(x))\n",
    "        alpha_k = 1/max_L(x,a)\n",
    "        e_k = np.zeros(len(x))\n",
    "        e_k[index] = grad[index]\n",
    "        x = x - (alpha_k*e_k)\n",
    "        grad = gradient(x,a)\n",
    "        it = it + 1\n",
    "        \n",
    "    if(verbose == True):\n",
    "        print('Iteracoes utilizadas = ', it)\n",
    "        print('f(x) final = ', apply_func(x,a))\n",
    "        \n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testar o algoritmo para funções de duas variáveis\n",
    "\n",
    "**i) Com maior $a_i$ igual a 1.1 vezes o menor**\n",
    "\n",
    "Fletcher-Reeves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracoes utilizadas =  8\n",
      "f(x) final =  0.7354020140405326\n",
      "Tempo de processamento: 0.0155 segundos\n",
      "Ponto de mínimo encontrado:  [-0.288352   -0.26212613]\n"
     ]
    }
   ],
   "source": [
    "a = np.float64([1,1.1]) # temos, por exemplo, esses valores de a > 0\n",
    "x = np.float64([1,2]) # e um chute inicial dos valores de xi\n",
    "start_time = time.clock()\n",
    "convergence_x = fletcher_reeves(x, a, tolerance=0.0001, verbose=True, backtracking=True, alpha=10)\n",
    "total_time = time.clock() - start_time\n",
    "print('Tempo de processamento: {:.4f} segundos'.format(total_time))\n",
    "print(\"Ponto de mínimo encontrado: \", convergence_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descenco Coordenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracoes utilizadas =  13\n",
      "f(x) final =  0.7354020142939202\n",
      "Tempo de processamento: 0.0070 segundos\n",
      "Ponto de mínimo encontrado:  [-0.28834959 -0.26211023]\n"
     ]
    }
   ],
   "source": [
    "a = np.float64([1,1.1]) # temos, por exemplo, esses valores de a > 0\n",
    "x = np.float64([1,2]) # e um chute inicial dos valores de xi\n",
    "start_time = time.clock()\n",
    "convergence_x = descenso_coordenado(x, a, tolerance=0.0001, verbose=True)\n",
    "total_time = time.clock() - start_time\n",
    "print('Tempo de processamento: {:.4f} segundos'.format(total_time))\n",
    "print(\"Ponto de mínimo encontrado: \", convergence_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise:** Podemos observar que apesar do fletcher-reeves convergir com menos iterações (8 iterações), o tempo necessário para a computação dessa convergência é superior a do descenso coordenado que utiliza mais iterações (13 iterações)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii) Com maior $a_i$ igual a 100 vezes o menor**\n",
    "\n",
    "Fletcher-Reeves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracoes utilizadas =  17\n",
      "f(x) final =  0.8259500689732878\n",
      "Tempo de processamento: 0.0120 segundos\n",
      "Ponto de mínimo encontrado:  [-0.35081482 -0.00350815]\n"
     ]
    }
   ],
   "source": [
    "a = np.float64([1,100]) # temos, por exemplo, esses valores de a > 0\n",
    "x = np.float64([1,2]) # e um chute inicial dos valores de xi\n",
    "start_time = time.clock()\n",
    "convergence_x = fletcher_reeves(x, a, tolerance=0.0001, verbose=True, backtracking=True, alpha=1)\n",
    "total_time = time.clock() - start_time\n",
    "print('Tempo de processamento: {:.4f} segundos'.format(total_time))\n",
    "print(\"Ponto de mínimo encontrado: \", convergence_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descenco Coordenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracoes utilizadas =  1515\n",
      "f(x) final =  0.8259500707521492\n",
      "Tempo de processamento: 0.0837 segundos\n",
      "Ponto de mínimo encontrado:  [-0.35078475 -0.00350835]\n"
     ]
    }
   ],
   "source": [
    "a = np.float64([1,100]) # temos, por exemplo, esses valores de a > 0\n",
    "x = np.float64([1,2]) # e um chute inicial dos valores de xi\n",
    "start_time = time.clock()\n",
    "convergence_x = descenso_coordenado(x, a, tolerance=0.0001, verbose=True)\n",
    "total_time = time.clock() - start_time\n",
    "print('Tempo de processamento: {:.4f} segundos'.format(total_time))\n",
    "print(\"Ponto de mínimo encontrado: \", convergence_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise:** Já para esta função, podemos observar que a diferença de iterações necessárias para convergir é muito maior, o que também é refletido pelo tempo de processamento utilizado em cada técnica. Dessa forma, podemos afirmar que há evidências da técnica de fletcher-reeves funcionar melhor do que o descenso coordenado, principalmente para autovalores mais discrepantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando valores de n\n",
    "\n",
    "**n = 3**\n",
    "- Fletcher-Reeves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracoes utilizadas =  98\n",
      "f(x) final =  1.9400140393958273e-07\n",
      "Tempo =  0.021430965566783367\n"
     ]
    }
   ],
   "source": [
    "a = np.float64(range(3)) # temos, por exemplo, esses valores de a > 0\n",
    "x = np.float64(range(3)) # e um chute inicial dos valores de xi\n",
    "start_time = time.clock()\n",
    "fletcher_reeves(x, a, tolerance=0.0001, verbose=True, backtracking=True, alpha=1)\n",
    "total_time = time.clock() - start_time\n",
    "print('Tempo = ', total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Descenso Coordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracoes utilizadas =  120049\n",
      "f(x) final =  0.00010000257822731737\n",
      "Tempo =  6.351482522468709\n"
     ]
    }
   ],
   "source": [
    "a = np.float64(range(3)) # temos, por exemplo, esses valores de a > 0\n",
    "x = np.float64(range(3)) # e um chute inicial dos valores de xi\n",
    "start_time = time.clock()\n",
    "descenso_coordenado(x, a, tolerance=0.0001, verbose=True)\n",
    "total_time = time.clock() - start_time\n",
    "print('Tempo = ', total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**n = 4**\n",
    "- Fletcher-Reeves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracoes utilizadas =  226\n",
      "f(x) final =  1.7483189430461824e-05\n",
      "Tempo =  0.03560613923850653\n"
     ]
    }
   ],
   "source": [
    "a = np.float64(range(4)) # temos, por exemplo, esses valores de a > 0\n",
    "x = np.float64(range(4)) # e um chute inicial dos valores de xi\n",
    "start_time = time.clock()\n",
    "fletcher_reeves(x, a, tolerance=0.0001, verbose=True, backtracking=True, alpha=1)\n",
    "total_time = time.clock() - start_time\n",
    "print('Tempo = ', total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Descenso Coordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracoes utilizadas =  240073\n",
      "f(x) final =  0.00010000309802756798\n",
      "Tempo =  10.430672233570366\n"
     ]
    }
   ],
   "source": [
    "a = np.float64(range(4)) # temos, por exemplo, esses valores de a > 0\n",
    "x = np.float64(range(4)) # e um chute inicial dos valores de xi\n",
    "start_time = time.clock()\n",
    "descenso_coordenado(x, a, tolerance=0.0001, verbose=True)\n",
    "total_time = time.clock() - start_time\n",
    "print('Tempo = ', total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise:** Pode-se concluir que o método de gradiente conjugado não linear é mais resistente a valores maiores de n. Todavia, é possível observar que o aumento do tempo necessário de computação aumenta consideravelmente com o aumento do n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Pelos experimentos conduzidos, podemos observar que há uma diferença considerável no desempenho dessas técnicas. Em particular, o algoritmo de gradiente conjugados não-linear com fletcher-reeves obteve melhores resultados, principalmente quando consideram-se funções com autovalores mais discrepantes, assim como com funções com $n$ grandes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
